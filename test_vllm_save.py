"""
æ–‡ä»¶å: eval_vllm_save.py
åŠŸèƒ½: ä½¿ç”¨ Swift VllmEngine è¿›è¡Œå¹¶è¡Œæ¨ç†ï¼Œè®¡ç®—è¯¦ç»†æŒ‡æ ‡ï¼Œå¹¶ä¿å­˜å¸¦ Summary çš„æ ‡å‡† JSON æ–‡ä»¶ã€‚
"""
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "2,3,6,7"
import json
import numpy as np
import re
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')
from swift.llm import VllmEngine, InferRequest, RequestConfig

class SwiftVLLMEvaluator:
    def __init__(self, model_path: str, tensor_parallel_size: int = 1, gpu_memory_utilization: float = 0.9):
        print(f"ğŸš€ åˆå§‹åŒ– vLLM å¼•æ“: {model_path}")
        self.engine = VllmEngine(
            model_id_or_path=model_path,
            tensor_parallel_size=tensor_parallel_size,
            gpu_memory_utilization=gpu_memory_utilization
        )

    def load_test_data(self, test_file: str) -> List[Dict]:
        print(f"ğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
        data = []
        with open(test_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    try: data.append(json.loads(line))
                    except: pass
        return data

    def prepare_infer_requests(self, data: List[Dict]) -> Tuple[List[InferRequest], List[int]]:
        system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„å·¥ä¸šè§†è§‰å¼‚å¸¸æ£€æµ‹åŠ©æ‰‹,éœ€ç²¾å‡†åˆ†æå›¾åƒå˜åŒ–ã€‚"
        user_prompt_template = """ä½ æ˜¯å·¥ä¸šè´¨æ£€äººå‘˜, è¯·å¯¹æ¯”ä¸‹é¢ä¸¤å¼ åŒä¸€ä½ç½®ä¸åŒæ—¶é—´çš„äº§å“å›¾åƒ,è¯·åˆ†æåä¸€å¼ å›¾ç‰‡ç›¸å¯¹äºå‰ä¸€å¼ å›¾ç‰‡å‘ç”Ÿçš„å˜åŒ–,å°†äº§å“çš„å¼‚å¸¸å˜åŒ–ç»“æœä»¥åŒ…å«"status"å’Œ"changes"é”®çš„JSONæ ¼å¼è¾“å‡º,"changes"ä¸­æ¯ä¸ªå˜åŒ–åŒ…å«"bbox"å’Œ"description"é”®ã€‚
å¦‚æœäº§å“æ²¡æœ‰å‘ç”Ÿå¼‚å¸¸å˜åŒ–,åˆ™ç›´æ¥è¾“å‡º:
{
"status": "æ— å¼‚å¸¸",
"changes": []
}
å¦‚æœäº§å“å‘ç”Ÿå¼‚å¸¸å˜åŒ–ï¼Œç”¨bboxæ¡†æ ‡æ³¨å‡ºæ¯ä¸ªå˜åŒ–çš„åŒºåŸŸ,å¹¶åˆ†åˆ«ç”¨ä¸€å¥è¯æè¿°è¯¥åŒºåŸŸçš„å¼‚å¸¸å˜åŒ–,ä¾‹å¦‚:
{
"status": "å¼‚å¸¸",
"changes": [
    {
    "bbox": [x1, y1, x2, y2],
    "description": "fold on the leather"
    },
    {
    "bbox": [x1, y1, x2, y2],
    "description": "rough on the tile"
    }
]
}"""
        requests = []
        indices = []
        for idx, sample in enumerate(data):
            images = sample.get('images', [])
            if not images and 'image_a_path' in sample:
                images = [sample['image_a_path'], sample['image_b_path']]
            if len(images) < 2: continue

            messages = [
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": user_prompt_template},
                        {"type": "image", "image": images[0]},
                        {"type": "image", "image": images[1]}
                    ]
                }
            ]
            requests.append(InferRequest(messages=messages))
            indices.append(idx)
        return requests, indices

    def extract_thinking_and_response(self, output_text: str) -> Tuple[str, str]:
        think_start = output_text.find('<think>')
        think_end = output_text.find('</think>')
        thinking = ""
        response = output_text
        if think_start != -1 and think_end != -1:
            thinking = output_text[think_start + 7:think_end].strip()
            response = output_text[think_end + 8:].strip()
        return thinking, response

    def parse_json_response(self, response_text: str) -> Dict:
        clean_text = re.sub(r'^```json\s*', '', response_text.strip(), flags=re.MULTILINE)
        clean_text = re.sub(r'^```\s*', '', clean_text, flags=re.MULTILINE)
        clean_text = clean_text.strip('`').strip()
        try: return json.loads(clean_text)
        except:
            start = clean_text.find('{')
            end = clean_text.rfind('}') + 1
            if start != -1 and end > start:
                try: return json.loads(clean_text[start:end])
                except: pass
        return {"status": "è§£æå¤±è´¥", "changes": []}

    def calculate_iou(self, box1, box2):
        try:
            x1_min, y1_min, x1_max, y1_max = box1
            x2_min, y2_min, x2_max, y2_max = box2
            inter_xmin = max(x1_min, x2_min)
            inter_ymin = max(y1_min, y2_min)
            inter_xmax = min(x1_max, x2_max)
            inter_ymax = min(y1_max, y2_max)
            if inter_xmax < inter_xmin or inter_ymax < inter_ymin: return 0.0
            inter_area = (inter_xmax - inter_xmin) * (inter_ymax - inter_ymin)
            box1_area = (x1_max - x1_min) * (y1_max - y1_min)
            box2_area = (x2_max - x2_min) * (y2_max - y2_min)
            union_area = box1_area + box2_area - inter_area
            return inter_area / union_area if union_area > 0 else 0.0
        except: return 0.0

    def process_and_save_results(self, data: List[Dict], results: List[Any], indices: List[int], output_file: str):
        print("\nğŸ“Š æ­£åœ¨è®¡ç®—è¯¦ç»†ç»Ÿè®¡æŒ‡æ ‡...")
        
        # --- ç»Ÿè®¡è®¡æ•°å™¨ ---
        stats = {
            'total': 0,
            'normal_gt_count': 0,      # çœŸå€¼æ˜¯æ­£å¸¸çš„æ•°é‡
            'anomaly_gt_count': 0,     # çœŸå€¼æ˜¯å¼‚å¸¸çš„æ•°é‡
            'normal_correct': 0,       # æ­£å¸¸æ ·æœ¬åˆ¤æ–­æ­£ç¡®çš„æ•°é‡
            'anomaly_correct': 0,      # å¼‚å¸¸æ ·æœ¬åˆ¤æ–­æ­£ç¡®çš„æ•°é‡ (çŠ¶æ€æ­£ç¡®)
            'bbox_correct': 0,         # IoU > 0.5 çš„æ•°é‡
            'total_iou': 0.0           # ç”¨äºè®¡ç®— mIoU
        }

        processed_samples = []

        for i, resp in enumerate(results):
            idx = indices[i]
            sample = data[idx]
            
            # 1. è·å–è¾“å…¥
            images = sample.get('images', [])
            if not images and 'image_a_path' in sample:
                images = [sample['image_a_path'], sample['image_b_path']]
            
            # 2. è§£æè¾“å‡º
            full_output = resp.choices[0].message.content
            thinking, json_text = self.extract_thinking_and_response(full_output)
            pred_json = self.parse_json_response(json_text)
            
            # 3. è·å–çœŸå€¼
            gt_data = sample.get('solution') or sample.get('label') or {}
            
            # --- 4. æ ¸å¿ƒæŒ‡æ ‡è®¡ç®— ---
            gt_status = gt_data.get('status', 'æ— å¼‚å¸¸')
            pred_status = pred_json.get('status', 'æœªçŸ¥')
            
            is_gt_anomaly = (gt_status == 'å¼‚å¸¸')
            is_correct_status = (gt_status == pred_status)
            
            stats['total'] += 1
            if is_gt_anomaly:
                stats['anomaly_gt_count'] += 1
                if is_correct_status: stats['anomaly_correct'] += 1
            else:
                stats['normal_gt_count'] += 1
                if is_correct_status: stats['normal_correct'] += 1
            
            # è®¡ç®— IoU (ä»…å¯¹ GT=å¼‚å¸¸ ä¸” Pred=å¼‚å¸¸ çš„æƒ…å†µè®¡ç®—ï¼Œå…¶ä»–æƒ…å†µ IoU=0)
            max_iou = 0.0
            if is_gt_anomaly and pred_status == 'å¼‚å¸¸':
                gt_changes = gt_data.get('changes', [])
                pred_changes = pred_json.get('changes', [])
                
                if gt_changes and pred_changes:
                    # ç®€åŒ–é€»è¾‘ï¼šå¯¹æ¯ä¸ª pred æ‰¾æœ€å¤§çš„ GT åŒ¹é…
                    # æ³¨æ„ï¼šä¸¥æ ¼è¯„æµ‹å¯èƒ½éœ€è¦åŒˆç‰™åˆ©åŒ¹é…ï¼Œè¿™é‡Œåšç®€å•å¯è§†åŒ–è¯„ä¼°å³å¯
                    current_ious = []
                    for p_box in pred_changes:
                        best_box_iou = 0.0
                        for g_box in gt_changes:
                            if 'bbox' in p_box and 'bbox' in g_box:
                                iou = self.calculate_iou(p_box['bbox'], g_box['bbox'])
                                best_box_iou = max(best_box_iou, iou)
                        current_ious.append(best_box_iou)
                    
                    if current_ious:
                        max_iou = max(current_ious) # å–é¢„æµ‹æ¡†ä¸­æœ€å¥½çš„ä¸€ä¸ªå±•ç¤º
                        stats['total_iou'] += np.mean(current_ious) # å¹³å‡ IoU ç´¯åŠ 
                    
                    if max_iou >= 0.5:
                        stats['bbox_correct'] += 1

            # æ„é€ æ ·æœ¬æ•°æ®
            result_item = {
                "id": idx,
                "image_a": images[0],
                "image_b": images[1],
                "gt": gt_data,
                "pred": pred_json,
                "thinking": thinking,
                "metrics": {
                    "status_correct": is_correct_status,
                    "max_iou": max_iou
                }
            }
            processed_samples.append(result_item)

        # --- 5. æ±‡æ€» Summary ---
        summary_metrics = {
            "total_samples": stats['total'],
            "accuracy_all": round((stats['normal_correct'] + stats['anomaly_correct']) / stats['total'], 4) if stats['total'] > 0 else 0,
            
            # æ­£å¸¸æ ·æœ¬ç»Ÿè®¡
            "normal_count": stats['normal_gt_count'],
            "normal_acc": round(stats['normal_correct'] / stats['normal_gt_count'], 4) if stats['normal_gt_count'] > 0 else 0,
            
            # å¼‚å¸¸æ ·æœ¬ç»Ÿè®¡
            "anomaly_count": stats['anomaly_gt_count'],
            "anomaly_acc": round(stats['anomaly_correct'] / stats['anomaly_gt_count'], 4) if stats['anomaly_gt_count'] > 0 else 0,
            
            # å®šä½ç»Ÿè®¡ (åˆ†æ¯ä¸º GT æ˜¯å¼‚å¸¸çš„æ•°é‡ï¼Œè¿˜æ˜¯æ£€æµ‹å‡ºå¼‚å¸¸çš„æ•°é‡ï¼Œè¿™é‡Œé€šå¸¸ç”¨ GT å¼‚å¸¸æ•°é‡ä½œä¸ºå¬å›å‚è€ƒï¼Œæˆ–ç”¨æ£€æµ‹å‡ºçš„ä½œä¸ºå‡†ç¡®å‚è€ƒ)
            # è¿™é‡Œè®¡ç®—ï¼šåœ¨æ‰€æœ‰ GT æ˜¯å¼‚å¸¸çš„æ ·æœ¬ä¸­ï¼ŒæˆåŠŸå®šä½ (IoU>0.5) çš„æ¯”ä¾‹
            "bbox_recall_iou05": round(stats['bbox_correct'] / stats['anomaly_gt_count'], 4) if stats['anomaly_gt_count'] > 0 else 0,
            "detected_anomalies": stats['anomaly_correct'] # æ­£ç¡®æ£€æµ‹å‡ºæ˜¯å¼‚å¸¸çš„ä¸ªæ•°
        }

        final_output = {
            "summary": summary_metrics,
            "data": processed_samples
        }

        print(f"\nğŸ“ˆ è¯„ä¼°å®Œæˆ:")
        print(f"   Total: {stats['total']}")
        print(f"   Acc: {summary_metrics['accuracy_all']:.2%}")
        print(f"   Normal Acc: {summary_metrics['normal_acc']:.2%} ({stats['normal_correct']}/{stats['normal_gt_count']})")
        print(f"   Anomaly Acc: {summary_metrics['anomaly_acc']:.2%} ({stats['anomaly_correct']}/{stats['anomaly_gt_count']})")

        with open(output_file, 'w', encoding='utf-8') as f_out:
            json.dump(final_output, f_out, ensure_ascii=False, indent=2)

        print(f"âœ… ç»“æœå·²ä¿å­˜è‡³: {output_file}")

    def run(self, test_file: str, output_file: str):
        data = self.load_test_data(test_file)
        infer_requests, indices = self.prepare_infer_requests(data)
        request_config = RequestConfig(max_tokens=2048, temperature=0.01, top_p=0.9) # æ¸©åº¦è°ƒä½ï¼Œä¿è¯ç¨³å®šæ€§
        
        print(f"ğŸš€ å¼€å§‹æ¨ç† ({len(infer_requests)} æ ·æœ¬)...")
        results = self.engine.infer(infer_requests, request_config=request_config, use_tqdm=True)
        self.process_and_save_results(data, results, indices, output_file)

if __name__ == "__main__":
   # MODEL_PATH = "/data0/jycheng/homework/MLLM_qwen3vl/sft/finetune/v11-20251228-003741/checkpoint-20"
    # MODEL_PATH = "/data0/limh/models/Qwen3-VL-2B-Thinking"
    MODEL_PATH = "/data0/jycheng/homework/MLLM_qwen3vl/output/qwen3vl_2b/v9-20251229-025757/checkpoint-138"#GRPOå¼ºåŒ–å­¦ä¹ åçš„æ¨¡å‹
    TEST_FILE = "/data0/jycheng/homework/MLLM_qwen3vl/dataset/å¤§æ¨¡å‹ä½œä¸šæ•°æ®é›†/test.jsonl"#æµ‹è¯•é›†
    OUTPUT_FILE = "/data0/jycheng/homework/MLLM_qwen3vl/test_results_grpo.json" # ç¡®ä¿æ˜¯ .json
    
    evaluator = SwiftVLLMEvaluator(MODEL_PATH, tensor_parallel_size=2)
    evaluator.run(TEST_FILE, OUTPUT_FILE)